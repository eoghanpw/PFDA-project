{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Programming for Data Analytics Project\n",
    "# Analysis of Wind Speed Data\n",
    "\n",
    "*Author: Eoghan Walsh*\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "from matplotlib.ticker import AutoMinorLocator\n",
    "import seaborn as sns\n",
    "import csv\n",
    "import re\n",
    "import requests\n",
    "from io import StringIO\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import Point"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Folder containing CSV files.\n",
    "csv_folder = './data/hourly/'\n",
    "\n",
    "# Regex pattern to find start of data.\n",
    "regex_pattern = \"^date(?!:)\"\n",
    "\n",
    "# Initialize an empty list to store DataFrames\n",
    "dataframes = []\n",
    "\n",
    "# Loop through all files in the folder.\n",
    "for csv_file in os.listdir(csv_folder):\n",
    "    # Check if the file is a CSV\n",
    "    if csv_file.endswith('.csv'):\n",
    "        # Construct the full file path\n",
    "        file_path = os.path.join(csv_folder, csv_file)\n",
    "\n",
    "        with open(file_path) as f:\n",
    "            reader = csv.reader(f)\n",
    "            \n",
    "            station_name = \",\".join(next(reader)).split(\"Station Name: \")[1].lower()\n",
    "\n",
    "            for row_number, row in enumerate(reader, start=0):\n",
    "                if any(re.search(regex_pattern, string) for string in row):\n",
    "                    break\n",
    "        \n",
    "        # Read the CSV file into a DataFrame\n",
    "        df = pd.read_csv(file_path, skiprows=row_number,low_memory=False)\n",
    "        \n",
    "        # Optionally, add a column to track the source file\n",
    "        df['station_name'] = station_name\n",
    "        df['source_file'] = csv_file\n",
    "\n",
    "        # Append the DataFrame to the list\n",
    "        dataframes.append(df)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_dataframe = pd.concat(dataframes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>ind</th>\n",
       "      <th>rain</th>\n",
       "      <th>ind.1</th>\n",
       "      <th>temp</th>\n",
       "      <th>ind.2</th>\n",
       "      <th>wetb</th>\n",
       "      <th>dewpt</th>\n",
       "      <th>vappr</th>\n",
       "      <th>rhum</th>\n",
       "      <th>...</th>\n",
       "      <th>ind.4</th>\n",
       "      <th>wddir</th>\n",
       "      <th>station_name</th>\n",
       "      <th>source_file</th>\n",
       "      <th>ww</th>\n",
       "      <th>w</th>\n",
       "      <th>sun</th>\n",
       "      <th>vis</th>\n",
       "      <th>clht</th>\n",
       "      <th>clamt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>01-dec-1955 01:00</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>10.7</td>\n",
       "      <td>0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>9.4</td>\n",
       "      <td>11.8</td>\n",
       "      <td>91</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>170</td>\n",
       "      <td>roches point</td>\n",
       "      <td>hly1075.csv</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>01-dec-1955 02:00</td>\n",
       "      <td>0</td>\n",
       "      <td>2.9</td>\n",
       "      <td>0</td>\n",
       "      <td>9.8</td>\n",
       "      <td>0</td>\n",
       "      <td>9.7</td>\n",
       "      <td>10.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>99</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>190</td>\n",
       "      <td>roches point</td>\n",
       "      <td>hly1075.csv</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>01-dec-1955 03:00</td>\n",
       "      <td>0</td>\n",
       "      <td>3.8</td>\n",
       "      <td>0</td>\n",
       "      <td>9.7</td>\n",
       "      <td>0</td>\n",
       "      <td>9.5</td>\n",
       "      <td>9.4</td>\n",
       "      <td>11.7</td>\n",
       "      <td>97</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>160</td>\n",
       "      <td>roches point</td>\n",
       "      <td>hly1075.csv</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>01-dec-1955 04:00</td>\n",
       "      <td>0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0</td>\n",
       "      <td>9.8</td>\n",
       "      <td>0</td>\n",
       "      <td>9.7</td>\n",
       "      <td>9.4</td>\n",
       "      <td>11.9</td>\n",
       "      <td>98</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>140</td>\n",
       "      <td>roches point</td>\n",
       "      <td>hly1075.csv</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>01-dec-1955 05:00</td>\n",
       "      <td>0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0</td>\n",
       "      <td>8.9</td>\n",
       "      <td>0</td>\n",
       "      <td>8.7</td>\n",
       "      <td>8.3</td>\n",
       "      <td>11.1</td>\n",
       "      <td>97</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>330</td>\n",
       "      <td>roches point</td>\n",
       "      <td>hly1075.csv</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                date  ind rain  ind.1  temp  ind.2  wetb dewpt vappr rhum  \\\n",
       "0  01-dec-1955 01:00    0  0.0      0  10.7      0  10.0   9.4  11.8   91   \n",
       "1  01-dec-1955 02:00    0  2.9      0   9.8      0   9.7  10.0  12.0   99   \n",
       "2  01-dec-1955 03:00    0  3.8      0   9.7      0   9.5   9.4  11.7   97   \n",
       "3  01-dec-1955 04:00    0  0.8      0   9.8      0   9.7   9.4  11.9   98   \n",
       "4  01-dec-1955 05:00    0  0.3      0   8.9      0   8.7   8.3  11.1   97   \n",
       "\n",
       "   ... ind.4  wddir  station_name  source_file   ww    w  sun  vis clht clamt  \n",
       "0  ...   1.0    170  roches point  hly1075.csv  NaN  NaN  NaN  NaN  NaN   NaN  \n",
       "1  ...   1.0    190  roches point  hly1075.csv  NaN  NaN  NaN  NaN  NaN   NaN  \n",
       "2  ...   1.0    160  roches point  hly1075.csv  NaN  NaN  NaN  NaN  NaN   NaN  \n",
       "3  ...   1.0    140  roches point  hly1075.csv  NaN  NaN  NaN  NaN  NaN   NaN  \n",
       "4  ...   1.0    330  roches point  hly1075.csv  NaN  NaN  NaN  NaN  NaN   NaN  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_dataframe.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_dataframe = final_dataframe[[\"date\", \"rain\", \"temp\", \"wdsp\", \"station_name\", \"source_file\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 8842594 entries, 0 to 448391\n",
      "Data columns (total 6 columns):\n",
      " #   Column        Dtype \n",
      "---  ------        ----- \n",
      " 0   date          object\n",
      " 1   rain          object\n",
      " 2   temp          object\n",
      " 3   wdsp          object\n",
      " 4   station_name  object\n",
      " 5   source_file   object\n",
      "dtypes: object(6)\n",
      "memory usage: 472.2+ MB\n"
     ]
    }
   ],
   "source": [
    "final_dataframe.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_dataframe.loc[:, 'date'] = pd.to_datetime(final_dataframe.loc[:, 'date'], format=\"%d-%b-%Y %H:%M\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 8842594 entries, 0 to 448391\n",
      "Data columns (total 6 columns):\n",
      " #   Column        Dtype \n",
      "---  ------        ----- \n",
      " 0   date          object\n",
      " 1   rain          object\n",
      " 2   temp          object\n",
      " 3   wdsp          object\n",
      " 4   station_name  object\n",
      " 5   source_file   object\n",
      "dtypes: object(6)\n",
      "memory usage: 472.2+ MB\n"
     ]
    }
   ],
   "source": [
    "final_dataframe.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_dataframe.loc[:, 'rain'] = pd.to_numeric(final_dataframe.loc[:, 'rain'], errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_dataframe.loc[:, 'temp'] = pd.to_numeric(final_dataframe.loc[:, 'temp'], errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_dataframe.loc[:, 'wdsp'] = pd.to_numeric(final_dataframe.loc[:, 'wdsp'], errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 8842594 entries, 0 to 448391\n",
      "Data columns (total 6 columns):\n",
      " #   Column        Dtype \n",
      "---  ------        ----- \n",
      " 0   date          object\n",
      " 1   rain          object\n",
      " 2   temp          object\n",
      " 3   wdsp          object\n",
      " 4   station_name  object\n",
      " 5   source_file   object\n",
      "dtypes: object(6)\n",
      "memory usage: 472.2+ MB\n"
     ]
    }
   ],
   "source": [
    "final_dataframe.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './data/download-file-list-hourly.txt'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 86\u001b[0m\n\u001b[0;32m     82\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m dataframes\n\u001b[0;32m     85\u001b[0m \u001b[38;5;66;03m# Call the function.\u001b[39;00m\n\u001b[1;32m---> 86\u001b[0m dataframes \u001b[38;5;241m=\u001b[39m daily_weather()\n",
      "Cell \u001b[1;32mIn[13], line 29\u001b[0m, in \u001b[0;36mdaily_weather\u001b[1;34m()\u001b[0m\n\u001b[0;32m     26\u001b[0m regex_pattern \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39mcompile(regex, re\u001b[38;5;241m.\u001b[39mIGNORECASE)\n\u001b[0;32m     28\u001b[0m \u001b[38;5;66;03m# Read the URLs from the txt file and strip newlines.\u001b[39;00m\n\u001b[1;32m---> 29\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(txt_file) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[0;32m     30\u001b[0m     csv_urls \u001b[38;5;241m=\u001b[39m [line\u001b[38;5;241m.\u001b[39mstrip() \u001b[38;5;28;01mfor\u001b[39;00m line \u001b[38;5;129;01min\u001b[39;00m f \u001b[38;5;28;01mif\u001b[39;00m line\u001b[38;5;241m.\u001b[39mstrip()]\n\u001b[0;32m     32\u001b[0m \u001b[38;5;66;03m# Loop through the URLs.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\eogha\\anaconda3\\Lib\\site-packages\\IPython\\core\\interactiveshell.py:324\u001b[0m, in \u001b[0;36m_modified_open\u001b[1;34m(file, *args, **kwargs)\u001b[0m\n\u001b[0;32m    317\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m}:\n\u001b[0;32m    318\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    319\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIPython won\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt let you open fd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m by default \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    320\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    321\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myou can use builtins\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m open.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    322\u001b[0m     )\n\u001b[1;32m--> 324\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m io_open(file, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './data/download-file-list-hourly.txt'"
     ]
    }
   ],
   "source": [
    "# Function to import daily weather data to dataframes.\n",
    "def daily_weather():\n",
    "\n",
    "    # File containing csv URLs.\n",
    "    txt_file = \"./data/download-file-list-hourly.txt\"\n",
    "\n",
    "    # Regex pattern to find the start of useful data in CSV files.\n",
    "    regex = r\"^date(?!:)\"\n",
    "\n",
    "    # Columns to import to dataframe.\n",
    "    columns = [\"date\", \"wdsp\", \"rain\", \"temp\"]\n",
    "\n",
    "    # Set index in dataframe.\n",
    "    index = \"date\"\n",
    "\n",
    "    # Numeric columns.\n",
    "    numeric_columns = [\"wdsp\", \"rain\", \"temp\"]\n",
    "\n",
    "    # Convert index to datetime.\n",
    "    date_format = \"%d-%b-%Y %H:%M\"\n",
    "\n",
    "    # Dictionary to store the dataframes.\n",
    "    dataframes = {}\n",
    "\n",
    "    # Regex pattern to find the column header row in CSV files.\n",
    "    regex_pattern = re.compile(regex, re.IGNORECASE)\n",
    "\n",
    "    # Read the URLs from the txt file and strip newlines.\n",
    "    with open(txt_file) as f:\n",
    "        csv_urls = [line.strip() for line in f if line.strip()]\n",
    "\n",
    "    # Loop through the URLs.\n",
    "    for url in csv_urls:\n",
    "        try:\n",
    "            # Send GET request to the URL.\n",
    "            response = requests.get(url)\n",
    "            if response.status_code != 200:\n",
    "                print(f\"Failed to retrieve the CSV file. Status code: {response.status_code}\")\n",
    "                continue\n",
    "\n",
    "            # Treat response content as file-like object.\n",
    "            csv_content = response.text\n",
    "            csv_file = StringIO(csv_content)\n",
    "\n",
    "            # Find the row with colum headers.\n",
    "            csv_reader = csv.reader(csv_file)\n",
    "            for row_number, row in enumerate(csv_reader):\n",
    "                row_string = \",\".join(row)\n",
    "                if regex_pattern.search(row_string):\n",
    "                    #print(f\"Skipped {row_number} rows in {url}\")\n",
    "                    break\n",
    "            else:\n",
    "                print(f\"Error finding regex pattern: \\\"{regex_pattern.pattern}\\\" in {url}\")\n",
    "                continue\n",
    "\n",
    "            # Reset the file pointer get weather station name.\n",
    "            csv_file.seek(0)\n",
    "            for row in csv_reader:\n",
    "                row_string = \",\".join(row)\n",
    "                df_name = row_string.split(\"Station Name: \")[1].lower()\n",
    "                break\n",
    "            else:\n",
    "                print(f\"Could not extract Station Name from {url}\")\n",
    "                df_name = url.split(\"webdata/\")[1].rstrip(\".csv\")\n",
    "                continue\n",
    "            \n",
    "            # Reset the file pointer and import the data to DataFrame.\n",
    "            csv_file.seek(0)\n",
    "            dataframes[df_name] = pd.read_csv(csv_file, skiprows=row_number, index_col=index, usecols=columns, low_memory=False)\n",
    "            \n",
    "            # Convert index to datetime.\n",
    "            dataframes[df_name].index = pd.to_datetime(dataframes[df_name].index, format=date_format)\n",
    "\n",
    "            # Convert data to numeric.\n",
    "            for col in numeric_columns:\n",
    "                dataframes[df_name][col] = pd.to_numeric(dataframes[df_name][col], errors=\"coerce\")\n",
    "            print(f\"Imported {url} as {df_name}\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"An error occurred while processing {url} ({df_name}): {e}\")\n",
    "\n",
    "    return dataframes\n",
    "\n",
    "\n",
    "# Call the function.\n",
    "dataframes = daily_weather()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'dict' object has no attribute 'count'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[26], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m dataframes\u001b[38;5;241m.\u001b[39mcount()\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'dict' object has no attribute 'count'"
     ]
    }
   ],
   "source": [
    "dataframes.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "## Look at the historical windspeed data.\n",
    "\n",
    "* Hourly/Daily/Monthly/Yearly\n",
    "* Wind ranges for windfarms to operate\n",
    "* Analysis of time of day/year\n",
    "* Power usage trends\n",
    "* Wind generation \n",
    "* https://public.tableau.com/views/Electricity-EnhancedMonthlyPanels/6?:language=en-US&:increment_view_count=no&:embed=y&:sid=&:redirect=auth&:embed_code_version=3&:loadOrderID=0&:display_count=y&:tabs=n&:origin=viz_share_link\n",
    "* https://www.seai.ie/data-and-insights/seai-statistics/monthly-energy-data/electricity-monthly#comp000064913259000000056f1221\n",
    "* https://www.eirgrid.ie/grid/system-and-renewable-data-reports\n",
    "- https://cms.eirgrid.ie/sites/default/files/publications/System-Data-Qtr-Hourly-December-2024.xlsx\n",
    "- https://cms.eirgrid.ie/sites/default/files/publications/System-Data-Qtr-Hourly-2022-2023_0.xlsx\n",
    "- https://cms.eirgrid.ie/sites/default/files/publications/System-Data-Qtr-Hourly-2020-2021.xlsx\n",
    "- https://cms.eirgrid.ie/sites/default/files/publications/System-Data-Qtr-Hourly-2018-2019.xlsx\n",
    "- https://cms.eirgrid.ie/sites/default/files/publications/System-Data-Qtr-Hourly-2016-2017.xlsx\n",
    "- https://cms.eirgrid.ie/sites/default/files/publications/System-Data-Qtr-Hourly-2014-2015.xlsx\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "## Predict future windspeed trends.\n",
    "* KNN\n",
    "* Decision trees\n",
    "* Power output of wind farms"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
